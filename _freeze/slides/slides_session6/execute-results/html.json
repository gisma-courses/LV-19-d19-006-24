{
  "hash": "098a11911dbc8ffedf1b8827b7eaef51",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Change detection part 1\"\nsubtitle: \"gdalcubes and STAC - new dimensions in time series and change detection analysis\"\nauthor: \"Chris Reudenbach\"\nexecute:\n  eval: false\n  echo: true\ntitle-slide-attributes:\n  data-background-image: slide1/preview-image-mof.png\n  #data-background-size: contain\n  data-background-opacity: \"0.5\"\nformat:\n  revealjs:\n    theme: [../_extensions/metropolis-theme/metropolis.scss]\n    toc: false\n    toc-depth: 2\n    chalkboard: true\n    slide-number: true\n    footer: <gisma 2024>\n    menu: true\nlightbox: true\nspotlight:\n      useAsPointer: true\n      size: 5\n---\n\n\n## Retrieving Sentinel data \n\n::: {.callout-important appearance=\"minimal\"}\n\n:::\n\n# Introduction\n\nSentinel-2 is currently the most important platform for Earth observation in all areas, but especially for climate change, land use and ecological issues at all levels, from the upper micro to the global scale.\n\nThere are two operational Sentinel-2 satellites: Sentinel-2A and Sentinel-2B, both in sun-synchronous polar orbits and 180 degrees out of phase. This arrangement allows them to cover the mid-latitudes with an orbital period of about 5 days.\n\nThe Sentinel-2 data are therefore predestined to record spatial and temporal changes on the Earth's surface (the forest was green in early summer, it has disappeared by late summer). They are ideal for timely studies before and after natural disasters, or for biomass balancing, etc.\n\n## Cloud-Optimised GeoTIFFs (COGs)\n\nUnfortunately, the official [Sentinel-2 archives](https://scihub.copernicus.eu/dhus/#/home) are anything but user-friendly. Even with very convenient tools such as [`sen2r`](https://sen2r.ranghetti.info/) it is sometimes tedious to process them.Technically, the processed product levels are available for download pre-processed as L1C and L2A products in JP2K format. The preferred file format is JP2K, which is storage efficient but has to be downloaded in its entirety locally by the user, resulting in high access costs and huge local storage requirements. The cloud-optimised GeoTIFFs (COGs) allow only the areas of interest to be downloaded and are also much faster to process. However, this requires optimised cloud services and a technically different access logic than in the processing chains used so far.\n\n## SpatioTemporal Asset Catalog (STAC)\n\nThe [Spatial-Temporal Asset Catalogue] (https://stacspec.org/) (STAC) provides a common language for simplified indexing and discovery of geospatial data. A \"Spatio-Temporal Asset\" is a file that contains information in a specific space and time.\n\nThis approach allows any provider of spatio-temporal data (imagery, SAR, point clouds, data cubes, full motion video, etc.) to provide Spatio-Temporal Asset Catalogues (STAC) for their data. STAC focuses on an easy-to-implement standard that organisations can use to make their data available in a durable and reliable way.\n\n[Element84](https://www.element84.com/) has provided a public API called Earth-search, a central search catalogue for all public AWS datasets using STAC (including the new Sentinel-2 COGs), which contains more than 11.4 million Sentinel-2 scenes worldwide as of 1 November 2017.\n\n# Goals\n\nThis example shows how complex times series methods from external R packages can be applied in cloud computing environments using [`[rstac`](https://cran.r-project.org/package=rstac) [@rstac] and [`gdalcubes`](https://cran.r-project.org/package=gdalcubes) [@gdalcubes]. We will use the [`bfast` R package](https://cran.r-project.org/package=bfast) containing unsupervised change detection methods identifying structural breakpoints in vegetation index time series. Specifically, we will use the `bfastmonitor()` function to monitor changes on a dedicated timeperiod of a time series of Sentinel-2 imagery.\n\nOther packages used in this tutorial include [`stars`](https://cran.r-project.org/package=stars) [@stars], [`tmap`](https://cran.r-project.org/package=tmap) [@tmap] and [mapview](https://cran.r-project.org/package=tmap) [@mapview] for creating interactive maps, [`sf`](https://cran.r-project.org/package=sf) [@sf] for processing vector data, and [`colorspace`](https://cran.r-project.org/package=colorspace) [@colorspace] for visualizations with accessible colors.\n\nVarious approaches to time series and difference analyses with different indices will be applied using the example of the MOF AOI for the time period 1997 - 2021.\n\n# Starting the Analysis\n\n## Setup the working environment\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\n# adapt your directory this is following the concept of the envimaR structure\ntutorialDir = path.expand(\"data/\")\n\nlibrary(sf)\nlibrary(raster)\nlibrary(tidyverse)\nlibrary(downloader)\nlibrary(tmap)\nlibrary(tmaptools)\nlibrary(mapview)\nlibrary(gdalcubes)\nlibrary(OpenStreetMap)\nlibrary(stars)\nlibrary(colorspace)\nlibrary(rstac)\n\n\nndvi.col = function(n) {\n  rev(sequential_hcl(n, \"Green-Yellow\"))\n}\n\nano.col = diverging_hcl(7, palette = \"Red-Green\",  register = \"rg\")\n```\n:::\n\n\n## Defining the Area of Interest\n\nOne major challenge is the fact that most of the earth surface related remote sensing activities are heavily *\"disturbed\"* by the atmosphere, especially by clouds. So to find cloud free satellite imagery is a common and cumbersome task. This task is supported by the `rstac` package which provides a convenient tool to find and filter adequate Sentinel-2 images out of the COG data storage. However, to address the AOI we need to provide the extend via the `bbox` argument of the corresponding function `stac_search()`. So first we need to derive and transform the required bounding box to WGS84 geo-coordinates, easily done with the `sf` functions `st_bbox()` and `st_transform()`. In addition we adapt the projection of the referencing vector objects to all other later projection needs.\n\n::::: boxSuccess\n<br>\n\n<p class=\"textline\">\n\nPlease note to project to three different CRS is for this examples convenience and clarity and somewhat superfluous. Only the corner coordinates of the sections are required and not the complete geometries. However, it creates more clarity for the later process to already have the data needed in different projections.\\\n\n</div>\n\n</p>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tmap)\nlibrary(tmaptools)\nutils::download.file(url=\"https://github.com/gisma/gismaData/raw/master/MOF/MOF_CORE.gpkg\",destfile=\"../data/MOF_CORE.gpkg\")\n\nforest_mask = st_read(\"../data/MOF_CORE.gpkg\")\nsf::st_crs(forest_mask) <- 4326\nfm=bb(forest_mask,projection=4326)\nforest_4326 =st_transform(forest_mask,crs = 4326)\nforest_3035 =st_transform(forest_mask,crs = 3035)\nforest_32632 =st_transform(forest_mask,crs = 32632)\n\n\n# call background map\nosm_forest <- tmaptools::read_osm(fm,type = \"bing\")\n\n# mapping the extents and boundaries of the choosen geometries\ntmap_mode(\"view\")\ntmap_options(check.and.fix = TRUE) + \n  tm_basemap(server = c(\"Esri.WorldGrayCanvas\", \"OpenStreetMap\", \"Esri.WorldTopoMap\",\"Esri.WorldImagery\")) +\n  tm_shape(forest_mask) +   \n  tm_polygons(alpha = 0.4, col=\"mainTreeSp\")\n```\n:::\n\n\nOur study area is pretty small, covering roughly 2.5 by 2.5 km forest area northwest of Marburg. The core part of the AOI is the Marburg Open Forest (MOF) a field research facility of the Philipps University Marburg.\n\n### Querying images with `rstac`\n\nUsing the `rstac` package, we first request all available images from 2017 to 2020 that intersect with our region of interest. Here, since the polygon has WGS84 as CRS, we do **not** need to transform the bounding box before using the `stac_search()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# search the data stack for the given period and area\nlibrary(rstac)\n\ns = stac(\"https://earth-search.aws.element84.com/v0\")\nitems <- s |>\n  stac_search(collections = \"sentinel-s2-l2a-cogs\",\n              bbox = c(st_bbox(forest_4326)[\"xmin\"],\n                       st_bbox(forest_4326)[\"ymin\"],\n                       st_bbox(forest_4326)[\"xmax\"],\n                       st_bbox(forest_4326)[\"ymax\"]), \n              datetime = \"2017-01-01/2024-11-30\",\n              limit = 5000) |>\n  post_request() \nitems\n\n# print date and time of first and last images\nrange(sapply(items$features, function(x) {x$properties$datetime}))\n```\n:::\n\n\nThis gives us 390 matching images recorded between Januar 2017 and December 2023.\n\n### Creating a monthly Sentinel-2 data cube\n\nTo obtain a Sentinel data cube, a gdalcube image collection must be created from the STAC query result. To do this, the asset names must be explicitly named in order to apply the SCL channel with the quality characteristics per pixel (classification as clouds, cloud shadows, etc.). In this query, a filter is set to cloud cover <= 50%.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gdalcubes)\nassets = c(\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\", \"B07\",\"B08\",\"B8A\",\"B09\",\"B11\",\"SCL\")\ns2_collection = stac_image_collection(items$features, asset_names = assets, property_filter = function(x) {x[[\"eo:cloud_cover\"]] < 50}) \ns2_collection\n```\n:::\n\n\nThe result is 130 images, i.e. approx. 1.8 images per month, from which we can now create a data cube. To do this, we use the UTM bounding box of our polygon as a spatial boundary, a spatial resolution of 10 metres, a bilinear spatial interpolation (useful for the spatially lower-resolution sentinel channels) and calculate monthly median values for all pixel values from the available images of a month. In addition, we add a buffer (B) on each side of the cube.\n\n\n:::: boxSuccess\n<br>\n\n<p class=\"textline\">\n\nThe *gdalcube image collection* can be considered as a proxy structure object which will be applied on the COGs.\n\n</div>\n\n</p>\n\n\n::: {.cell messages='false' warnings='false'}\n\n```{.r .cell-code}\nb = 100\nv = cube_view(srs = \"EPSG:32632\", \n              dx = 10, \n              dy = 10, \n              dt = \"P1M\",  \n              aggregation = \"median\", \n              extent = list(t0 = \"2017-01-01\",\n                            t1 = \"2023-11-30\", \n                            left = st_bbox(forest_32632)[\"xmin\"] - b, \n                            right = st_bbox(forest_32632)[\"xmax\"] + b,\n                            bottom = st_bbox(forest_32632)[\"ymin\"] - b, \n                            top = st_bbox(forest_32632)[\"ymax\"] + b),\n              resampling = \"bilinear\")\nv\n```\n:::\n\n\nNext we create a data cube, subset the red and near infrared bands and crop by our polygon, which simply sets pixel values outside the polygon to NA. We then save the data cube as a single netCDF file. Note that this is not necessary, but saving intermediate results sometimes makes debugging easier, especially if the methods applied afterwards are computationally intensive.\n\n::: boxSuccess\n<br>\n\n<p class=\"textline\">\n\nOnly calling a final *action* will start the processing on the COG-Server. In this case 'write_ncdf'.\n\n</div>\n\n</p>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# we \"download\" the data and write it t a netcdf file\n  s2.mask = image_mask(\"SCL\", values = c(3,8,9))\n  gdalcubes_options(parallel = 16, ncdf_compression_level = 5)\n  raster_cube(s2_collection, v, mask = s2.mask) |>\n    write_ncdf(\"..data/MOF_10.nc\",overwrite=TRUE)\n```\n:::\n\n\nWe will show in the following examples a straightforward plotting in a generic pipe. However a more common visualization is pretty straightforward. A typical pipe could be: Save a resulting netCDF file `->` Convert it to a `stars` object `->` Visualize the results with `tmap`, `mapview`, `ggplot2` or whatever preferred package to create (interactive) map(s).\n\n## Reductions\n\nPossible reducers include `\"min\"`, `\"mean\"`, `\"median\"`, `\"max\"`, `\"count\"` (count non-missing values), `\"sum\"`, `\"var\"` (variance), and `\"sd\"` (standard deviation). Reducer expressions are always given as a string starting with the reducer name followed by the band name in parentheses. Notice that it is possible to mix reducers and bands.\n\n### Counting\n\nTo get an idea of the data, we can compute simple summary statistics applying a `reducer` function over dimensions. For example using the `count` reducer we learn about the temporal coverage for each aggregated pixel and hence an initial understanding of the data set temporal quality.\n\n\n::: {.cell messages='false' warnings='false'}\n\n```{.r .cell-code}\nncdf_cube(file.path(tutorialDir,\"MOF_10.nc\")) |>\n  reduce_time(\"count(B04)\") |> \n  plot(key.pos = 1, zlim=c(25,45), col = viridis::viridis, nbreaks = 10)\n```\n:::\n\n\nWe can see that most time series contain valid observations about 40 months, which should be sufficient for our example. Similarly, it is also possible to reduce over space, leading to summary time series.\n\nBelow you will find various examples dealing with the common NDVI and the [kNDVI](https://advances.sciencemag.org/content/7/9/eabc7447) Indices.\n\n### kNDVI\n\nBelow, we derive mean monthly kNdvi values over all pixel time series.\n\n\n::: {.cell messages='false' warnings='false'}\n\n```{.r .cell-code}\nncdf_cube(file.path(tutorialDir,\"MOF_10.nc\")) |>\n    apply_pixel(\"tanh(((B08-B04)/(B08+B04))^2)\", \"kNDVI\") |>\n  reduce_time(\"mean(kNDVI)\") |>\n  plot(key.pos = 1,  col = ndvi.col, nbreaks = 12)\n```\n:::\n\n\n## NDVI\n\nBelow, we derive mean monthly Ndvi values over all pixel time series.\n\n\n::: {.cell messages='false' warnings='false'}\n\n```{.r .cell-code}\nncdf_cube(file.path(tutorialDir,\"MOF_10.nc\")) |>\n  apply_pixel(\"(B08-B04)/(B08+B04)\", \"NDVI\") |>\n  reduce_time(\"mean(NDVI)\") |>\n  plot(key.pos = 1, zlim=c(-0.2,1), col = ndvi.col, nbreaks = 12)\n```\n:::\n\n\n### Zonal Statistics\n\n\n::: {.cell messages='false' warnings='false'}\n\n```{.r .cell-code}\nzstats = ncdf_cube(file.path(tutorialDir,\"MOF_10.nc\")) |>\n  apply_pixel(\"(B08-B04)/(B08+B04)\", \"NDVI\") |>\n  extract_geom(forest_32632,FUN = median) \n\nforest_32632$FID = rownames(forest_32632)\nx = merge(forest_32632, zstats, by = \"FID\")\nmapview(x[x$time == \"2018-07\", \"NDVI\"],col.regions = ndvi.col)\n```\n:::\n\n\n### Timeseries\n\n\n::: {.cell messages='false' warnings='false'}\n\n```{.r .cell-code}\nncdf_cube(file.path(tutorialDir,\"MOF_10.nc\")) |>\n  apply_pixel(\"tanh(((B08-B04)/(B08+B04))^2)\", \"kNDVI\") |>\n  reduce_space(\"min(kNDVI)\", \"max(kNDVI)\", \"mean(kNDVI)\") |>\n  plot(join.timeseries = TRUE)\n```\n:::\n\n\n### Calculate the annual NDVI difference - using functions\n\nThe following function will iterate through 3 years of NDVI data and calculating NDVI difference maps for each pair of years.\n\n\n::: {.cell messages='false' warnings='false'}\n\n```{.r .cell-code}\ngdalcubes_options(parallel =  12)\n\n# ndvi operand\nndvi_type = \"median(kNDVI)\"\n\n# time slots as tibble\nts = tibble(t0 = c(\"2018-04-01\",\"2019-04-01\",\"2020-04-01\",\"2021-04-01\"), \n            t1= c(\"2018-09-01\",\"2019-09-01\",\"2020-09-01\",\"2021-09-01\"))\n\n# names of the time slots\nnames_ndvi = paste(ts$t0,ts$t1,sep = \" to \")\n\nbasic_kndvi <- function(fncube=NULL, t0=NULL, t1=NULL) {\n  ncdf_cube(fncube) |> \n    select_bands(c(\"B04\", \"B08\")) |>\n    select_time(c(t0,t1)) |>\n  apply_pixel(\"tanh(((B08-B04)/(B08+B04))^2)\", \"kNDVI\") |>\n    reduce_time(ndvi_type)\n}\n\n# (stac-search -> stac and cloud filter image collection -> create cube -> call user function)\nndvi = list()\nfor (i in 1:nrow(ts)){\n  # call user function\n  basic_kndvi(fncube = file.path(tutorialDir,\"MOF_10.nc\"), t0 = ts$t0[i], t1 = ts$t1[i]) %>%\n    st_as_stars() -> ndvi[[i]]\n  \n}\n\n# now we may create a mask according to the NDVI extent and resolution\nstars::write_stars(ndvi[[1]] * 0, paste0(tutorialDir,\"forest/only_forestmask.tif\"))\ngi=link2GI::linkGDAL(searchLocation = \"/usr/bin/\")\ncmd=gi$bin[[1]]$gdal_bin[14]\nsystem(paste(cmd ,'-burn 1.0 -tr 10.0 10.0 -a_nodata 0.0 -te ', st_bbox(ndvi[[1]])$xmin,' ',st_bbox(ndvi[[1]])$ymin,' ',st_bbox(ndvi[[1]])$xmax,' ',st_bbox(ndvi[[1]])$ymax,' -ot Float32 -of GTiff', paste0(tutorialDir,\"forest/MOF_mask_pr.shp \"),paste0(tutorialDir,\"forest/only_forestmask.tif\")))\nmask <- raster(paste0(tutorialDir,\"forest/only_forestmask.tif\"))\nplot(mask)                                \n\nmask[mask == 0] = NA\n\n# mapping the results\ntmap_mode(\"plot\")\ntm_ndvi = lapply(seq(2:length(names_ndvi) -1),function(i){\n  m = tm_shape(osm_forest) + tm_rgb() +\n    tm_shape((ndvi[[i]] - ndvi[[i+1]]) * st_as_stars(mask )) +\n    tm_raster(title = ndvi_type,pal =diverging_hcl(11, \"rg\")) +\n    tm_layout(panel.labels = paste(\"Difference \",names_ndvi[[i]],\"/\",names_ndvi[[i+1]]),\n              legend.show = TRUE,\n              panel.label.color = \"darkblue\",\n              panel.label.size =0.5,\n              panel.label.height=1.2,\n              legend.text.size = 0.3,\n              legend.outside = TRUE) +\n    tm_grid()\n})\n\n\n# tmap_arrange(tm_ndvi,nrow = 1,asp = NA,widths = c(0.33,0.33,0.33),outer.margins = 0.001)\n```\n:::\n\n\n#### Resulting maps\n\n\n::: {.cell messages='false' warnings='false'}\n\n:::\n\n\n## Use case: Spatial identification of magnitudes and time periods of kNDVI changes\n\nTo apply a more complex time series method such as `bfastmonitor()`, the data cube operations below allow to provide custom user-defined R functions instead of string expressions, which translate to built-in reducers. It is very important that these functions receive arrays as input and must return arrays as output, too. Depending on the operation, the dimensionality of the arrays is different:\n\n| Operator | Input | Output |\n|:-----------------------|:-----------------------|:-----------------------|\n| `apply_pixel` | Vector of band values for one pixel | Vector of band values of one pixel |\n| `reduce_time` | Multi-band time series as a matrix | Vector of band values |\n| `reduce_space` | Three-dimensional array with dimensions bands, x, and y | Vector of band values |\n| `apply_time` | Multi-band time series as a matrix | Multi-band time series as a matrix |\n\nThere is almost no limit of what R function we use, but we must take care of a few things: 1. The reducer function is executed in a new R process without access to the current workspace. It is not possible to access variables defined outside of the function and packages must be loaded **within** the function. 2. The reducer function **must** always return a vector with the same length (for all time series). 3. It is a good idea to think about `NA` values, i.e. you should check whether the complete time series is `NA`, and that missing values do not produce errors.\n\nAnother possibility to apply R functions to data cubes is of course to convert data cubes to `stars` objects and use the `stars` package for further analysis.\n\n### Applying `bfastmonitor` as a user-defined reducer function\n\nIn our example, `bfastmonitor` returns change date and change magnitude values per time series so we can use `reduce_time()`. The script below (1) calculates the [kNDVI](https://advances.sciencemag.org/content/7/9/eabc7447), (2) applies `bfastmonitor()`, and properly handles errors e.g. due to missing data with `tryCatch()`, and (3) finally writes out the resulting change dates and magnitudes of change for all pixels of the time series as a netCDF file. The results shows the changes starting at 1/2019 until 12/2021 and identify pretty well the dynamical impacts of drought and bark beetle in the Marburg University Forest (MOF).\n\n\n::: {.cell messages='false' warnings='false'}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(tmap)\nlibrary(tmaptools)\nlibrary(gdalcubes)\nlibrary(stars)\nlibrary(colorspace)\nndvi.col = function(n) {\n  rev(sequential_hcl(n, \"Green-Yellow\"))\n}\ntutorialDir = path.expand(\"~/edu/agis/doc/data/tutorial/\")\n\nfigtrim <- function(path) {\n  img <- magick::image_trim(magick::image_read(path))\n  magick::image_write(img, path)\n  path\n}\ngdalcubes_options(parallel = 12)\n## start analysis\nsystem.time(\n  ncdf_cube(file.path(tutorialDir,\"MOF_10.nc\")) |>\n    reduce_time(names = c(\"change_date\", \"change_magnitude\",\"kndvi\"), FUN = function(x) {\n      kndvi = tanh(((x['B08',]-x['B04',])/(x['B08',]+x['B04',]))^2)\n      if (all(is.na(kndvi))) {\n        return(c(NA,NA))\n      }\n      kndvi_ts = ts(kndvi, start = c(2017, 1), frequency = 12)\n      library(bfast)\n      tryCatch({\n        result = bfastmonitor(kndvi_ts, start = c(2020,1), \n                              history = \"all\", level = 0.01)\n        return(c(result$breakpoint, result$magnitude))\n      }, error = function(x) {\n        return(c(NA,NA))\n      })\n    }) |>\n    write_ncdf(paste0(tutorialDir,\"bf_results.nc\"),overwrite = TRUE))\n```\n:::\n\n\nNow we can use the netCDF file and map the results with any preferred visualisation tool. In this case `tmap`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tmap)\n\nmask <- raster(paste0(tutorialDir,\"forest/only_forestmask.tif\"))\n# plotting it from the local ncdf  \ntmap_mode(\"view\")\ngdalcubes::ncdf_cube(paste0(tutorialDir,\"bf_results.nc\")) |>\n  stars::st_as_stars() -> x\ntm_shape(osm_forest) + tm_rgb() +\n  tm_shape(x[1] * st_as_stars(mask )) + \n  tm_raster(n = 6)  +\n  tm_layout(\n    legend.show = TRUE,\n    panel.label.height=0.6,\n    panel.label.size=0.6,\n    legend.text.size = 0.4,\n    legend.outside = TRUE) +\n  tm_grid()\n\ntm_shape(osm_forest) + tm_rgb() +\n  tm_shape(x[2]* st_as_stars(mask ))  + tm_raster() +\n  tm_layout(legend.title.size = 1,\n            panel.label.height=0.6,\n            panel.label.size=0.6,\n            legend.text.size = 0.4,\n            legend.outside = TRUE) +\n  tm_grid()\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n<iframe valign=\"center\" src=\"m2.html\" width=\"1024\" height=\"960\" frameborder=\"0\" allowfullscreen=\"allowfullscreen\">\n\n</iframe>\n\n<figcaption>*Magnitude Change Map* </figcaption>\n\n<p>\n\n<iframe valign=\"center\" src=\"m1.html\" width=\"1024\" height=\"960\" frameborder=\"0\" allowfullscreen=\"allowfullscreen\">\n\n</iframe>\n\n<figcaption>*Period of Change Map* </figcaption>\n\nRunning `bfastmonitor()` is computationally expensive. However, since in common (*not in our case*) the data should be located in the cloud, it would be obvious to launch one of the (payed) more powerful machine instance types with many processors. Parallelization within one instance can be controlled entirely by `gdalcubes` using `gdalcubes_options()` which is extremely simple.\n\nFrom a scientific point of view we need to tune some aspects. The kNDVI Index together with the `bfastmonitor` approach is somewhat sophisticated and need a validation strategy. Also the correlation to the different tree species could be promising. So there is certainly a need for more analysis to understand the processes and to identify false results.\n\n# Summary\n\nThis examples have shown, how simple and more more complex methods can be applied on data cubes. Especially the chosen approach to just *\"download\"* the data from a COG server and perform the processing on the local machine is kind of promising due to the fact that the code can be run almost identically on a cloud instance. The use of more common or well known functionalities and packages helps a lot migrating to `gdalcubes` concept.\n\nIt is even more powerful to use this workflow for extremely comfortable multisensor multiscale approaches.\n\n# References\n:::\n::::\n:::::\n\n\n\n------------------------------------------------------------------------\n\n## Minimum temperature (°C)\n\n::::: columns\n::: {.column width=\"45%\"}\n![CMIP6 downscaled future climate projection for 2061-2080 \\[model: CNRM-ESM2-1; ssp: “585”\\]](../assets/cmip.png)\n:::\n\n::: {.column width=\"45%\"}\n![WorldClim version 2.1 climate data for 1970-2000](../assets/wc.png)\n:::\n:::::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}