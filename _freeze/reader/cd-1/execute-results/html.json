{
  "hash": "cdce1a44517606fd97d9f32ab711fe10",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Change Detection - Klassifikationsverfahren \nauthor: Chris Reudenbach\ndate: '2021-12-16'\nbibliography: references.bib\nsubtitle: 'Clusteranalyse, Maximum-Likelihood and ML'\ntitle-block-banner: ../reader/images/harz2-sp.jpg\ntitle-block-banner-color: black\neditor: \n  markdown: \n    wrap: sentence\n---\n\n\nIn the geosciences, remote sensing is the only measurement technique that allows complete coverage of large spatial areas, up to the entire Earth's surface.\nIts successful application requires both the use of existing methods and the adaptation and development of new ones.\n\n# Introduction\n\nIn geospatial or environmental informatics, the detection of changes to the Earth's surface using satellite, aircraft or drone images, known as change detection analysis, is an important application.\nThese results are often linked to biophysical, geophysical or anthropogenic processes in order to gain both a deeper understanding and the possibility of developing predictive models.\nMethods of image analysis are of outstanding importance for generating spatial information from the underlying processes.\nSince both the quantity and quality of this \"image data\" are playing an increasingly important role in environmental monitoring and modeling, it is becoming more and more necessary to integrate \"big data\" concepts into the analyses.\nThis means performing reproducible analyses with large amounts of data (\\>\\> 10 GB).\nThis is essential for both scientific knowledge gain and future societal challenges.\n\nAs already explained in the introduction, we start with a scalable change detection analysis of forest damage in low mountain ranges, which is a typical application-oriented task.\nScalable means that we limit the analysis to a manageable area, the Nordwestharz, and to two time slices.\nHowever, the resulting algorithm can be applied to different or larger areas and to more time slices.\n\n## Information from image data\n\nUnprocessed satellite images are not necessarily informative.\nWhile our eyes can interpret a true-color image relatively conclusively and intuitively, a reliable and reproducible, i.e. scientifically sound, interpretation requires other approaches.\nA major advantage of typical image analysis methods over visual interpretation is the derivation of additional, so-called *invisible* information.\nWe have already calculated simple indices such as NDVI or surface albedo as a physically based conversion of image signals into a measured variable.\n\nTo obtain useful or meaningful information, e.g. about the land cover in an area, we have to analyze the data according to the question at hand.\nProbably the best known and most widely used approach is the supervised classification of image data into categories of interest.\n\nThis tutorial introduces you to the classification of satellite and aerial image data.\n\nWe will cover the following topics:\n\n1.  preparation of the working environment and loading of data\n2.  digitization of the training areas\n3.  unsupervised classification (kmeans clustering)\n4.  model training\n5.  supervised classification (Random Forest, Maximum Likelihood)\n6.  estimation of model quality\n\n# Classification of remote sensing data\n\nPlease note that all types of classification usually require extensive data pre-processing.\nThe focus is then on model building and quality assessment, which can be seen as the technical basis for classification, in order to finally derive the interpretation of the results in terms of content in the data post-processing.\nWe will go through this process step by step.\n\n## Supervised classification\n\nIn supervised land cover classification, a model is derived from a limited amount of training land cover data that predicts land cover for the entire data set.\nThe land cover types are defined *a priori*, and the model attempts to predict these types based on the similarity between the characteristics of the training data and the rest of the data set.\n\n![](images/supervised_classification.jpg)\n\nFrom a pragmatic point of view, classification tasks generally require the following steps:\n\n-   Creation of a comprehensive input data set that contains one or more raster layers. Selection of training areas, i.e. subsets of the input data set for which the land cover type is known to the remote sensing expert. Knowledge of the land cover can be obtained, for example, from one's own or third-party in situ observations, management information or other remote sensing products (e.g. high-resolution aerial photographs). Training a model using the training sites. For validation purposes, the training sites are often subdivided into one or more test and training sites to evaluate the performance of the model algorithm. Applying the trained model to the entire data set, i.e. predicting the land cover type based on the similarity of the data at each site to the class characteristics of the training data set.\n\n# Change Detection Forest Change Northwest Harz\n\nIn this tutorial, we will use the Sentinel-2 images from the previous exercise.\n\n## Start - Setting up the work environment\n\nYou can either use the data saved from the previous exercise or define, download and edit a new area.\nHowever, the work environment is usually loaded first.\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\n# ---- 0 Projekt Setup ----\nrequire(\"pacman\")\n# packages installing if necessary and loading\npacman::p_load(mapview, mapedit, tmap, tmaptools, raster, terra, stars, gdalcubes, sf, dplyr,CDSE, downloader, tidyverse,RStoolbox,rprojroot, exactextractr, randomForest, ranger, e1071, caret, link2GI, rstac, OpenStreetMap,colorspace)\n\n\n\n#--- Switch to determine whether digitization is required. If set to FALSE, the\nroot_folder = find_rstudio_root_file()\n\nndvi.col = function(n) {\n  rev(sequential_hcl(n, \"Green-Yellow\"))\n}\n\nano.col = diverging_hcl(7, palette = \"Red-Green\",  register = \"rg\")\n\nnclasses=2\n```\n:::\n\n\nPlease add any missing or defective packages in the above setup script (if error messages occur).\nOn the basis of the available Sentinel data, the first step should be to identify suitable data sets for a surface classification.\n\n## Step 1: Get an overview\n\nA closer look at the RGB images (RGB432B) shows that four data sets appear to be suitable due to the image quality and low cloud cover.\nThese are June 19 and July 24, 2019, and June 33 and July 30, 2020.\nThe May images were chosen because of the earlier growing season, as any growth on the cleared areas might be less visible here.\n\nFirst of all, this data must be available in a \"raster stack\", i.e. a multi-channel image.\n\n## Download\n\n\n::: {.cell}\n\n```{.r .cell-code}\n####\nutils::download.file(url=\"https://github.com/gisma/gismaData/raw/master/MOF/MOF_CORE.gpkg\",destfile=\"../data/MOF_CORE.gpkg\")\nforest_mask = st_read(\"../data/MOF_CORE.gpkg\")\nsf::st_crs(forest_mask) <- 4326\nfm=bb(forest_mask,projection=4326)\n\n# forest_4326 =st_transform(forest_mask,crs = 4326)\n# forest_3035 =st_transform(forest_mask,crs = 3035)\n# forest_32632 =st_transform(forest_mask,crs = 32632)\n\n# mapping the extents and boundaries of the choosen geometries\ntmap_mode(\"view\")\ntmap_options(check.and.fix = TRUE) + \n  tm_basemap(server = c(\"Esri.WorldImagery\", \"Esri.WorldTopoMap\")) +\n  tm_shape(forest_mask) +   \n  tm_polygons(alpha = 0.4, col=\"mainTreeSp\")\n\n\n\nid <- Sys.getenv(\"CDSE_ID\")\nsecret <- Sys.getenv(\"CDSE_SECRET\")\nOAuthClient <- GetOAuthClient(id = id, secret = secret)\ncollections <- GetCollections(as_data_frame = TRUE)\ncollections\n\n\nimages <- SearchCatalog(bbox =cm, from = \"2018-05-01\", to = \"2021-05-31\", \n    collection = \"sentinel-2-l2a\", with_geometry = TRUE, client = OAuthClient)\n\nimages\n\nsummary(images$areaCoverage)\n\nday <- images[order(images$tileCloudCover), ]$acquisitionDate[1:20]\n\nscript_file_rb <- system.file(\"scripts\", \"RawBands.js\", package = \"CDSE\")\nscript_file_ndvi <- system.file(\"scripts\", \"NDVI_float32.js\", package = \"CDSE\")\nscript_file_tc <- system.file(\"scripts\", \"TrueColor.js\", package = \"CDSE\")\n\nr_rb <- GetImage(bbox =  ext, time_range = day[5], script = script_file_rb, \n                collection = \"sentinel-2-l2a\", format = \"image/tiff\", mosaicking_order = \"leastCC\", \n                resolution = 10, mask = TRUE, buffer = 100, client = OAuthClient)\nnames(r_rb) = c(\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B09\", \"B11\", \"B12\")\nterra::plot(r_rb, main = paste(names(r_rb), day), cex.main = 0.75)\n\nr_ndvi <- GetImage(bbox =  fm, time_range = day[5], script = script_file_ndvi, \n                collection = \"sentinel-2-l2a\", format = \"image/tiff\", mosaicking_order = \"leastCC\", \n                resolution = 10, mask = TRUE, buffer = 100, client = OAuthClient)\nnames(r_ndvi) = c(\"NDVI\")\nterra::plot(r_ndvi, main = paste(names(r_ndvi), day), cex.main = 0.75)\n\nr_tc <- GetImage(bbox =  fm, time_range = day[5], script = script_file_tc, \n                collection = \"sentinel-2-l2a\", format = \"image/tiff\", mosaicking_order = \"leastCC\", \n                resolution = 10, mask = TRUE, buffer = 100, client = OAuthClient)\nnames(r_tc) = c( \"B02\", \"B03\", \"B04\")\nterra::plotRGB(r_tc, main = paste(\"true color B02, B03, B04\"), cex.main = 0.75)\n\nimages <- SearchCatalog(bbox = fm, from = \"2018-01-01\", to = \"2023-12-31\",\n                        collection = \"sentinel-2-l2a\", with_geometry = TRUE, \n                        filter = \"eo:cloud_cover < 5\", client = OAuthClient)\n\n\n\n\nimages <- SearchCatalog(aoi = forest_mask, from = \"2018-01-01\", to = \"2023-12-31\",\n                        collection = \"sentinel-2-l2a\", with_geometry = TRUE, \n                        filter = \"eo:cloud_cover < 10\", client = OAuthClient)\n# Get the day with the minimal cloud cover for every month -----------------------------\ntmp1 <- images[, c(\"tileCloudCover\", \"acquisitionDate\")]\ntmp1$month <- lubridate::month(images$acquisitionDate)\nagg1 <- stats::aggregate(tileCloudCover ~ month, data = tmp1, FUN = min)\ntmp2 <- merge.data.frame(agg1, tmp1, by = c(\"month\", \"tileCloudCover\"), sort = FALSE)\n# in case of ties, get an arbitrary date (here the smallest acquisitionDate, \n# could also be the biggest)\nagg2 <- stats::aggregate(acquisitionDate ~ month, data = tmp2, FUN = min)\nmonthly <- merge.data.frame(agg2, tmp2, by = c(\"acquisitionDate\", \"month\"), sort = FALSE)\n\ndays <- monthly$acquisitionDate\n# Retrieve images in parallel ----------------------------------------------------------\nscript_file <- system.file(\"scripts\", \"NDVI_float32.js\", package = \"CDSE\")\ntmp_folder <- tempfile(\"dir\")\n\nlstRast <- lapply(days, GetImageByTimerange, bbox = fm, collection = \"sentinel-2-l2a\",\n    script = script_file, file = NULL, format = \"image/tiff\", mosaicking_order = \"mostRecent\",\n    resolution = 10, buffer = 0, mask = TRUE, client = OAuthClient,\n    url = getOption(\"CDSE.process_url\"))\n\n# Plot the images ----------------------------------------------------------------------\npar(mfrow = c(3, 4))\nsapply(seq_along(days), FUN = function(i) {\n     ras <- lstRast[[i]]\n     day <- days[i]\n     #ras[ras < 0] <- 0\n     terra::plot(ras, main = paste(\"MOF NDVI on\", day), range = c(0, 1),\n            cex.main = 0.7, pax = list(cex.axis = 0.5), plg = list(cex = 0.5),\n            col = colorRampPalette(c(\"darkred\", \"yellow\", \"darkgreen\"))(99))\n     })\n```\n:::\n\n\n### Preparation of the data\n\nAs soon as the download has been successful, the actual classification can begin.\nFirst, the data must be organized in a technically suitable way as a multichannel image.\nIn addition, a current or temporally corresponding Corine land use data set is loaded to generate a binary forest/non-forest mask.\nThe already available Copernicus account can be used to download the Corine data (https://land.copernicus.eu/pan-european/corine-land-cover).\nAfter the (manual) download, unzip the data into the subdirectory 'level0' (be careful, there are countless subdirectories here after unzipping the archive).\nWe need the file `U2018_CLC2018_V2020_20u1.tif`.\nAlternatively, the already correctly processed and projected \\*data set from the github repository (see script) can be used.\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\n#--- Reading the data from the directories\n\n##--- This describes how to process the Corine land use and land cover dataset\n## The necessary file can also be downloaded from the repository\n## An account is required for the download https://land.copernicus.eu/pan-european/corine-land-cover\n## Therefore, download the data manually and copy it into the directory and unzip it\n## Then execute the commented snippet below\n\n# corine_eu = raster(file.path(envrmt$path_data_lev0,\"u2018_clc2018_v2020_20u1_raster100m/DATA/U2018_CLC2018_V2020_20u1.tif\"))\n# tmp = projectRaster(pred_stack_2019[[1]],crs = crs(corine_eu))\n# corine_crop = raster::crop(corine_eu,tmp)\n# corine_utm = projectRaster(corine_crop,crs = crs(pred_stack_2019))\n# corine = resample(corine_utm,pred_stack_2019[[1]])\n# raster::writeRaster(corine,file.path(envrmt$path_data_lev0,\"/corine.tif\"),overwrite=TRUE)\n\n# Alternatively, download the example data set\nutils::download.file(url=\"https://github.com/gisma/gismaData/raw/master/geoinfo/corine.tif\",destfile=file.path(root_folder,\"data/corine.tif\"))\ncorine = rast(file.path(root_folder,\"data/corine.tif\"))\nplot(corine)\n\n# Create a forest mask\n# Agro-forestry areas code=22, Broad-leaved forest code=23,\n# Coniferous forest code=24, Mixed forest code=25\nmask = classify(corine,c(-100,22,0,22,26,1,26,500,0))\nplot(mask)\n\n# RGB stack of the two years\nutils::download.file(url=\"https://github.com/gisma/gismaData/raw/master/geoinfo/corine.tif\",destfile=file.path(root_folder,\"data/corine.tif\"))\nutils::download.file(url=\"https://github.com/gisma/gismaData/raw/master/geoinfo/corine.tif\",destfile=file.path(root_folder,\"data/corine.tif\"))\npred_stack_2019 = raster::stack(list.files(file.path(envrmt$path_data_lev1,\"BOA\"),pattern = \"20190619\",full.names = TRUE))\npred_stack_2020 = raster::stack(list.files(file.path(envrmt$path_data_lev1,\"BOA\"),pattern = \"20200623\",full.names = TRUE))\n\n\n# Stack loop over the data\nfor (pat in c(\"EVI\", \"MSAVI2\", \"NDVI\", \"SAVI\")){\npred_stack_2019 = raster::stack(pred_stack_2019, stack(list.files(file.path(envrmt$path_data_lev1, pat), pattern = \"20190619\", full.names = TRUE)))\npred_stack_2020 = raster::stack(pred_stack_2020,stack(list.files(file.path(envrmt$path_data_lev1,pat),pattern = \"20200623\",full.names = TRUE)))\n}\n# get rid of NA\npred_stack_2019 = reclassify(pred_stack_2019, cbind(NA, 0))\npred_stack_2020 = reclassify(pred_stack_2020, cbind(NA, 0))\n\n# Assign human-readable names to the data layers\nnames(pred_stack_2019) = c(\"band1\", \"band2\", \"band3\", \"band4\", \"band5\", \"band6\", \"band7\", \"band8\", \"band9\", \"band10\", \"band11\", \"EVI\", \"MSAVI2\", \"NDVI\", \"SAVI\")\nnames(pred_stack_2020) = c(\"band1\", \"band2\", \"band3\", \"band4\", \"band5\", \"band6\", \"band7\", \"band8\", \"band9\", \"band10\", \"band11\", \"EVI\", \"MSAVI2\", \"NDVI\", \"SAVI\")\nsaveRDS(pred_stack_2019,paste0(envrmt$path_data,\"pred_stack_2019.rds\"))\nsaveRDS(pred_stack_2020,paste0(envrmt$path_data,\"pred_stack_2020.rds\"))\npred_stack_2019 = readRDS(paste0(envrmt$path_data,\"pred_stack_2019.rds\"))\npred_stack_2020 = readRDS(paste0(envrmt$path_data,\"pred_stack_2020.rds\"))\n\n\n# visual inspection of the stacks\nplot(pred_stack_2019)\nplot(pred_stack_2020)\n```\n:::\n\n\n### First impression – K-means cluster classification\n\nProbably the best-known unsupervised classification technique is K-means clustering, which is also referred to as the *\"simplest machine learning algorithm\"*.\nIt is often used to obtain an initial overview of whether the raster data can be sufficiently separated in feature space.\n\nIn our example (applied to 5 classes and executed with the function `unsuperClass` from the `RStoolbox` package), this looks as follows.\nThe cluster algorithm can achieve a fairly acceptable separation of the clearings/bald spots with 5 clusters, which makes a classification seem promising.\nAlso experiment with other cluster settings and discuss the results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## k-means über RStoolbox\n# Modell\nprediction_kmeans_2019 = RStoolbox::unsuperClass(pred_stack_2019, nClasses = 5,norm = TRUE, algorithm = \"MacQueen\")\n# Klassifikation\nplot(prediction_kmeans_2019$map)\n\nprediction_kmeans_2020 = RStoolbox::unsuperClass(pred_stack_2020, nClasses = 5,norm = TRUE, algorithm = \"MacQueen\")\nplot(prediction_kmeans_2020$map)\n```\n:::\n\n\n![](images/kmeans-2020.png) ![](images/kmeans-2019.png)\n\n## Step 2 - Generating training data\n\nFor a supervised classification, we need data that indicates which surface class defined areas of the satellite image belong to.\nThis data is referred to as training data and is very often obtained by manual digitization.\nThis can be done quite comfortably in RStudio if only a few training areas have to be digitized quickly and effectively.\n\nFor larger tasks, it makes sense to use the convenient method described in the QGIS 3.16 documentation, for example in the [digitizing tutorial](https://docs.qgis.org/3.16/en/docs/training_manual/create_vector_data/create_new_vector.html#basic-ty-digitizing-polygons).\n\n## Digitizing training data\n\nWe assume that we want to classify two types of land cover: *clearcut* and *other*.\nWith mapedit, each class must be digitized individually.\nOnce the training areas are available as vector data, the features of the respective raster stack can be extracted into a table according to the digitized classes and corrected for possible missing values.\n\n\n\nIf this part has already been completed, the logical variable *digitize* (defined at the beginning of the script) can be set to *FALSE* and the *else* part of the branch can be run – in other words, only the existing data is read.\n\n\n## Excursus: Creating training areas with mapedit \n\n### Using color composites for better training results\n\nFor this exercise, we use `mapedit`, a small but powerful package that allows you to digitize and edit vector data in Rstudio or an external browser.\nIn combination with `mapview`, any \\[color composite\\] (https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/composites/) can also be used as a basis for digitization.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 = tm_shape(pred_stack_2019) + tm_rgb(r=4, g=3, b=2) +\n  tm_layout(legend.outside.position = \"right\",\n            legend.outside = T,\n            panel.label.height=0.6,\n            panel.label.size=0.6,\n            panel.labels = c(\"r=1, g=2, b=3\")) +\n  tm_grid()\n\nm2 = tm_shape(pred_stack_2019) + tm_rgb(r=8, g=4, b=3) +\n  tm_layout(legend.outside.position = \"right\",\n            legend.outside = T,\n            panel.label.height=0.6,\n            panel.label.size=0.6,\n            panel.labels = c(\"r=8, g=4, b=3\")) +\n  tm_grid()\ntmap::tmap_arrange(m1,m2)\n```\n:::\n\n\n![](images/rgb.png)\n\nThe planes can be switched using the plane control.\nIn true-color composites, the visible spectral channels Red (B04), Green (B03), and Blue (B02) are mapped to the corresponding red, green, and blue color channels, respectively, producing an image of the surface that closely resembles the natural \"color\" as it would be seen by a human sitting on the spacecraft.\nFalse color images are often created using the spectral channels for near-infrared, red, and green.\nThey are particularly useful for assessing vegetation because plants reflect near-infrared and green light while absorbing red light (red-edge effect).\nDense vegetation appears a darker red.\nCities and open ground appear gray or light brown, water appears blue or black.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#---- Digitization of training data ----\n\nif (digitize) {\n# For the supervised classification, we need training areas. You can digitize them as shown below or alternatively use QGis, for example\n\n# clearcut\n\n# For the false color composite r = 8, g = 4, b = 3, maxpixels = 1693870)\n# maxpixels has significantly higher memory requirements, vegetation in red\n# below the true color composite\ntrain_area_2019 <- mapview::viewRGB(pred_stack_2019, r = 4, g = 3, b = 2, maxpixels = 1693870) %>% mapedit::editMap()\n# Adding the attributes class (text) and id/year (integer)\nclearcut_2019 <- train_area_2019$finished$geometry %>% st_sf() %>% mutate(class = \"clearcut\", id = 1,year=2019)\ntrain_area_2020 <- mapview::viewRGB(pred_stack_2020, r = 4, g = 3, b = 2,maxpixels = 1693870) %>% mapedit::editMap()\nclearcut_2020 <- train_area_2020$finished$geometry %>% st_sf() %>% mutate(class = \"clearcut\", id = 1,year=2020)\n\n# other: all areas not belonging to clear cutting as representative as possible\ntrain_area_2019 <- mapview::viewRGB(pred_stack_2019, r = 4, g = 3, b = 2) %>% mapedit::editMap()\nother_2019 <- train_area_2019$finished$geometry %>% st_sf() %>% mutate(class = \"other\", id = 2,year=2019)\ntrain_area_2020 <- mapview::viewRGB(pred_stack_2020, r = 4, g = 3, b = 2) %>% mapedit::editMap()\nother_2020 <- train_area_2020$finished$geometry %>% st_sf() %>% mutate(class = \"other\", id = 2,year=2020)\n\ntrain_areas_2019_2020 <- rbind(clearcut_2019,clearcut_2020, other_2019,other_2020) # Reproject to the raster file\ntrain_areas_2019 = sf::st_transform(train_areas_2019_2020,crs = sf::st_crs(pred_stack_2019))\nmapview(filter(train_areas_2019_2020,year==2019), zcol=\"class\")\n# save geometries\nst_write(train_areas_2019_2020,paste0(envrmt$path_data,\"train_areas_2019_2020.gpkg\"))\n\n# Extract the training data for the digitized areas\ntDF_2019 = exactextractr::exact_extract(pred_stack_2019, filter(train_areas_2019_2020,year==2019), force_df = TRUE,\ninclude_cell = TRUE,include_xy = TRUE,full_colnames = TRUE,include_cols = \"class\")\ntDF_2020 = exactextractr::exact_extract(pred_stack_2020, filter(train_areas_2019_2020,year==2020), force_df = TRUE,\ninclude_cell = TRUE,include_xy = TRUE,full_colnames = TRUE,include_cols = \"class\")\n\n# again, copy together into a file\ntDF_2019 = dplyr::bind_rows(tDF_2019)\ntDF_2019$year = 2019\ntDF_2020 = dplyr::bind_rows(tDF_2020)\ntDF_2020$year = 2020\n# Delete any rows that contain NA (no data) values\ntDF_2019 = tDF_2019[complete.cases(tDF_2019) ,]\ntDF_2020 = tDF_2020[complete.cases(tDF_2020) ,]\n\ntDF= rbind(tDF_2019,tDF_2020)\n\n# check the extracted data\nsummary(tDF)\n\n# Save as R internal data format\n# is stored in the repo and can therefore be loaded (line below)\nsaveRDS(tDF, paste0(envrmt$path_data,\"tDF.rds\"))\n\n\n\n} else {\ntDF = readRDS(paste0(envrmt$path_data,\"tDF.rds\"))\n}\n```\n:::\n\n\nThe result is a table with training data for 2019 and 2020.\nThe data set contains all raster information for all bands covered by the polygons for the classes \"clearcut\" and \"other\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(tDF)\n```\n:::\n\n\n\n## Step 3 - Model training, testing model quality, classification\n\nClassifiers (e.g. the maximum likelihood classifier) or machine learning algorithms (such as Random Forest) use the training data to determine descriptive models that represent statistical signatures, classification trees or other functions.\nWithin the limits of the quality of the training data, such models are suitable and representative for making predictions for areas if the predictors from the model are available for the entire area.\n\nWe now want to predict the spatial characteristics of clear-felling/no forest using a maximum likelihood classification and random forest, and apply standard methods of random validation and model quality assessment.\n\nThe goal is to separate clearcuts from all other pixels and to quantify the differences between 2019 and 2020.\n\n### Maximum Likelihood Classification\n\nMaximum likelihood classification assumes that the distribution of data for each class and in each channel is normally distributed.\nUnder this assumption, the probability that a particular pixel belongs to a particular class is calculated.\nSince the probabilities can also be specified as a threshold, without this restriction, *all* pixels are assigned regardless of how unlikely they are.\nEach pixel is assigned to the class that has the highest probability (i.e., the maximum probability).\n\n![](images/max.png)\n\nSince the maximum likelihood algorithm requires training data, it is a supervised learning method.\nThis means that we, as users, have to provide the algorithm with data that conveys knowledge about the classes to be predicted.\nThis data is then divided into training and test data.\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\n# ---- Maximum Likelihood Classification ----\n\ntDF = readRDS(paste0(envrmt$path_data,\"tDF.rds\"))\n\n## Here the Random Forest is accessed via the caret utility package\n# Setting a \"seed\" enables reproducible randomness\nset.seed(123)\n\n# Randomly draw 15% of the data (training/test)\nidx = createDataPartition(tDF$class,list = FALSE,p = 0.05)\ntrainDat = tDF[idx,]\ntestDat = tDF[-idx,]\n\n# Response variable (= \"class\" column) must be of the \"factor\" data type\ntrainDat$class <- as.factor(trainDat$class)\ntestDat$class <- as.factor(testDat$class)\n\n\n# superClass() function from the RSToolbox package requires the table to be converted into the\n# required (old) SpatialdataPoint object\n\nsp_trainDat = trainDat\nsp_testDat = testDat \nsp::coordinates(sp_trainDat) = ~x+y\nsp::coordinates(sp_testDat) = ~x+y\ncrs(sp_trainDat) = crs(pred_stack_2019)\ncrs(sp_testDat) = crs(pred_stack_2019)\n\n\n# superClass method \"mlc\" trains the model and then classifies it\n#raster::beginCluster(30)\nprediction_mlc_2019 <- superClass(pred_stack_2019, trainData = sp_trainDat[,1:16],valData = sp_testDat[,1:16], responseCol = \"class\", model = \"mlc\", tuneLength = 1, trainPartition = 0.3,verbose = TRUE)\n\nprediction_mlc_2020 <- superClass(pred_stack_2020, trainData = sp_trainDat[,1:16],valData = sp_testDat[,1:16], responseCol = \"class\",model = \"mlc\", tuneLength = 1, trainPartition = 0.3,verbose = TRUE)\nsaveRDS(prediction_mlc_2019, paste0(envrmt$path_data,\"prediction_mlc_2019.rds\"))\nsaveRDS(prediction_mlc_2020, paste0(envrmt$path_data,\"prediction_mlc_2020.rds\"))\n```\n:::\n\n\n### Random forest\n\nRandom forests can be used for both regression and classification tasks, with the latter being particularly relevant in environmental remote sensing.\nLike any machine learning method, the random forest model learns to recognize patterns and structures in the data itself.\nSince the random forest algorithm also requires training data, it is also a supervised learning method.\n![](images/Random_forest_diagram_complete.png)!\n\nFigure: Simplified illustration of data classification by random forest during training.\nVenkata Jagannath \\[CC BY-SA 4.0\\] via wikipedia.org\n\nA random forest algorithm learns from the data by creating random decision trees – hence the name.\nFor classification tasks, the algorithm takes a suitable instance of a decision tree from the training data set and assigns the corresponding class to the pixel.\nThis is repeated with all available decision trees.\nFinally, the pixel is assigned to the class that has the most trees, according to the winner-takes-all principle.\n\n\n\n\n\n### Estimation model quality\n\nThe test data are now used for the independent quality check of the model.\nA confusion matrix indicates how accurately the model predicts the correct classes.\nThe main diagonal of the matrix indicates the cases in which the model applies.\nIn our classification of only two classes, however, a special case applies: [evaluation of a binary classifier](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers).\nDetailed explanations for the function used here can be found in the [caret help](https://topepo.github.io/caret/measuring-performance.html#measures-for-predicted-classes).\n\nThe main statements about model quality are:\n\n-   *'Positive' Class* = **clearcut**: is measured with the sensitivity (*true positive rate*), which indicates the probability that a positive object is correctly classified as positive.\n-   *'Negative Class'* = **other**: is measured with the specificity (*true negative rate*) and indicates the probability that a negative object is correctly classified as negative.\n-   *Positive and negative predictive values* indicate the actual performance for *clearcut* and *other*. They are corrected for the actual frequency distribution and are a measure of the precision and performance of the model with regard to the respective classes.\n\nDespite the high values, we see that the *clearcut* class drops off significantly here.\nThis can certainly be taken as an indication of the need to improve the classification.\n\nOverall, however, the model can be considered good.\n\n\n::: {.cell warnings='false'}\n\n:::\n\n\n### Prediction on the original data\n\nNow we are ready to apply the verified model to our data set.\nIn remote sensing, this is usually called classification.\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\n# Klassifikation (auch Vorhersage genannt)\nprediction_rf_2019  = raster::predict(pred_stack_2019 ,rf_model)\nprediction_rf_2020  = raster::predict(pred_stack_2020 ,rf_model)\nsaveRDS(prediction_rf_2019, paste0(envrmt$path_data,\"prediction_rf_2019.rds\"))\nsaveRDS(prediction_rf_2020, paste0(envrmt$path_data,\"prediction_rf_2020.rds\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction_rf_2019 = readRDS(paste0(envrmt$path_data,\"prediction_rf_2019.rds\"))\nprediction_rf_2020 = readRDS(paste0(envrmt$path_data,\"prediction_rf_2020.rds\"))\nprediction_mlc_2019 = readRDS(paste0(envrmt$path_data,\"prediction_mlc_2019.rds\"))\nprediction_mlc_2020 = readRDS(paste0(envrmt$path_data,\"prediction_mlc_2020.rds\"))\n## ---- Visualisierung mit mapview ----\nmapview::mapshot(mapview::viewRGB(mask*pred_stack_2020, r = 4, g =3, b = 2,maxpixels =  1693870)+\n  mapview(mask*prediction_rf_2019 , alpha.regions = 0.5, maxpixels =  1693870,\n          col.regions = mapviewPalette(\"mapviewRasterColors\"),at = seq(0, nclasses, 1), legend = TRUE) +\n  mapview(mask*prediction_rf_2020, alpha.regions = 0.5, maxpixels =  1693870,\n          col.regions = mapviewPalette(\"mapviewRasterColors\"),at = seq(0, nclasses, 1), legend = FALSE) +\n  mapview(mask*prediction_mlc_2019$map,alpha.regions = 0.5, maxpixels =  1693870,\n          col.regions = mapviewPalette(\"mapviewRasterColors\"),at = seq(0, nclasses, 1), legend = FALSE) +\n  mapview(mask*prediction_mlc_2020$map,alpha.regions = 0.5, maxpixels =  1693870,\n          col.regions = mapviewPalette(\"mapviewRasterColors\"),at = seq(0, nclasses, 1), legend = FALSE),url = \"compare-class.html\")\n```\n:::\n\n\n<iframe valign=\"center\" src=\"compare-class.html\" width=\"1024\" height=\"960\" frameborder=\"0\" allowfullscreen=\"allowfullscreen\">\n\n</iframe>\n\n<figcaption>*Comparison of the two years and RF and MLC classification* </figcaption>\n\n<p>\n\nA visual comparison shows that the Random Forest and Maximum Likelihood classifications provide results of comparable quality.\nBut does this impression stand up to quantitative analysis?\n\n\n## Further support\n\n\nConsider the following resources as examples of how a specific conceptual and technical approach to answering a question can be *\"crystallized\"* step by step from the wide range of instructions available on the internet.\nAfter a lot of research and critical cross-checking, a *\"state of research\"* that is currently considered to be certain within the scientific community can be identified, which can be regarded as a sufficient basis for good scientific practice.\n\nWork/read through the following selection of blogs and guides, even for practice purposes.\n\n-   Robert J. Hijmans [rspatial - supervised classification](https://rspatial.org/raster/rs/5-supclassification.html)\n-   Ivan Lizarazo [RPubs Tutorial](https://rpubs.com/ials2un/rf_landcover)\n-   Sydney Goldstein [blog](https://urbanspatial.github.io/classifying_satellite_imagery_in_R/)\n-   João Gonçalves [supervised classification](https://www.r-exercises.com/2018/03/07/advanced-techniques-with-raster-data-part-2-supervised-classification/)\n-   Valentin Stefan [pixel-based supervised classification](https://valentinitnelav.github.io/satellite-image-classification-r/)\n\nIn the articles, you will always find both technical instructions and conceptual or specific technical questions and solutions.\nThey are by no means a substitute for specialized scientific knowledge.\nBut they show how technical and conceptual understanding can be developed step by step and, by \"replicating\" and applying, support the skills needed to approach questions independently.\n\nI would like to explicitly quote Valentin Stefan, the author of the blog post [pixel-based supervised classification](https://valentinitnelav.github.io/satellite-image-classification-r/):\n\n::: {.callout-note appearance=\"minimal\"}\n*\"\\[...\\] Consider this content a blog post and nothing more. It does not claim to be an exhaustive exercise or a substitute for your critical thinking \\[...\\].\"* :::\n:::\n\nYou can download all the necessary scripts and data from the github repository (https://github.com/gisma/geoinfo/archive/refs/heads/main.zip).\nAlternatively, you can also set up the repo as a project in Rstudio (Rstudio github (https://www.r-bloggers.com/2015/07/rstudio-and-github/).\n\\>\n",
    "supporting": [
      "cd-1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}